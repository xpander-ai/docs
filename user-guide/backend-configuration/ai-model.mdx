---
title: "AI Model"
description: "Choose your LLM provider and manage API keys"
icon: "brain"
mode: "wide"
---

There are two ways to control the AI model of your agents running on xpander.

**Centrally Managed** - xpander-provided API keys to the Model provider and model ID you select in the Agent Workbench (recommended).

**Bring Your Own Model** - Use your own API keys with any LLM provider client directly in the code.

<Note>
When you configure the model provider and model name in the Agent Workbench UI, xpander automatically provides the appropriate native client class to your agent at runtime, handling all the provider-specific setup and configuration for you.
</Note>

<CodeGroup>

```python Bring Your Own Model
from xpander_sdk import Backend
from agno.agent import Agent, OpenAIChat

backend = Backend()
agno_agent = Agent(**backend.get_args(override={'model': OpenAIChat(api_key='your-openai-key')}))
agno_agent.print_response(message="What's your role?")
```

```python Centrally Managed
from xpander_sdk import Backend
from agno.agent import Agent

backend = Backend()
agno_agent = Agent(**backend.get_args())
agno_agent.print_response(message="What's your role?")
```

</CodeGroup>

## Key Differences

**Centrally Managed (Recommended):**
- No API key management in your code
- Model configuration handled automatically by xpander
- Simpler setup with just `backend.get_args()`
- Secure - API keys managed centrally

**Bring Your Own Model:**
- You provide your own API key directly in the code
- Manual model configuration with `override` parameter
- More control but requires API key management
- Useful when you need to use your own API keys or custom model configurations
