---
title: "AI Model"
description: "Choose your LLM provider and manage API keys"
icon: "brain"
mode: "wide"
---

## Serverless Deployment

- **Built-in LLM**: Use xpander's provided API keys (recommended)
- **Custom Models**: Configure your own API keys via workbench UI

## Dedicated Deployment  

- **Any Model**: Full flexibility - local models, custom endpoints, any provider

<CodeGroup>

```python Built-in LLM (Serverless)
from xpander_sdk import Backend
from agno.agent import Agent

backend = Backend()
agno_agent = Agent(**backend.get_args())
```

```python Custom Models (Serverless/Dedicated)
from xpander_sdk import Backend
from agno.agent import Agent, OpenAIChat, Ollama, OpenAILike
from os import getenv

backend = Backend()

# Serverless: Uses keys from workbench UI or hardcoded override
agno_agent = Agent(**backend.get_args(override={
    'model': OpenAIChat(api_key='your-key')
}))

# Dedicated: Local models
agno_agent = Agent(**backend.get_args(override={
    'model': Ollama(id="gpt-oss:20b")
}))

# Dedicated: Custom endpoints  
agno_agent = Agent(**backend.get_args(override={
    'model': OpenAILike(
        id="mistralai/Mixtral-8x7B-Instruct-v0.1",
        api_key=getenv("TOGETHER_API_KEY"),
        base_url="https://api.together.xyz/v1",
    )
}))
```

</CodeGroup>