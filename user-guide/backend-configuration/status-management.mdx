---
title: "Status Management"
description: "Advanced agent status management using AgentExecutionStatus for monitoring, debugging, and operational excellence"
icon: "chart-line"
---

# Status Management

**Status Management** in xpander.ai provides comprehensive monitoring and control over agent execution states using the `AgentExecutionStatus` enumeration. This guide covers advanced patterns for building robust status tracking, monitoring, and operational systems.

## Overview

Effective status management enables:

<CardGroup cols={2}>
<Card title="Real-time Monitoring" icon="chart-line">
Track agent execution states and performance metrics in real-time
</Card>

<Card title="Operational Intelligence" icon="brain">
Gain insights into agent behavior and system health
</Card>

<Card title="Automated Recovery" icon="arrows-rotate">
Implement automated recovery mechanisms based on status transitions
</Card>

<Card title="Debugging Support" icon="bug">
Enhanced debugging capabilities through detailed status tracking
</Card>
</CardGroup>

## AgentExecutionStatus Deep Dive

### Status Transitions and Lifecycle

Understanding the complete status lifecycle:

```python
from xpander_sdk import Backend, on_boot, on_shutdown, on_task
from xpander_sdk.types import AgentExecutionStatus
import asyncio
import time
from typing import Dict, List, Optional, Callable
from dataclasses import dataclass, field
from enum import Enum

@dataclass
class StatusTransition:
    """Represents a status transition with metadata."""
    from_status: AgentExecutionStatus
    to_status: AgentExecutionStatus
    timestamp: float = field(default_factory=time.time)
    reason: Optional[str] = None
    metadata: Dict[str, any] = field(default_factory=dict)
    duration_seconds: Optional[float] = None

class StatusManagerError(Exception):
    """Custom exception for status management errors."""
    pass

class AdvancedStatusManager:
    """Advanced status management system with transitions tracking."""
    
    def __init__(self):
        self.current_status = AgentExecutionStatus.Pending
        self.status_history: List[StatusTransition] = []
        self.status_start_time = time.time()
        self.status_callbacks: Dict[AgentExecutionStatus, List[Callable]] = {}
        self.transition_callbacks: Dict[tuple, List[Callable]] = {}
        self.metrics = {
            "total_transitions": 0,
            "status_durations": {},
            "error_count": 0,
            "recovery_count": 0
        }
        
        # Valid status transitions
        self.valid_transitions = {
            AgentExecutionStatus.Pending: [
                AgentExecutionStatus.Executing,
                AgentExecutionStatus.Failed,
                AgentExecutionStatus.Stopped
            ],
            AgentExecutionStatus.Executing: [
                AgentExecutionStatus.Paused,
                AgentExecutionStatus.Completed,
                AgentExecutionStatus.Error,
                AgentExecutionStatus.Failed,
                AgentExecutionStatus.Stopped
            ],
            AgentExecutionStatus.Paused: [
                AgentExecutionStatus.Executing,
                AgentExecutionStatus.Stopped,
                AgentExecutionStatus.Failed
            ],
            AgentExecutionStatus.Error: [
                AgentExecutionStatus.Executing,  # Retry
                AgentExecutionStatus.Failed,
                AgentExecutionStatus.Stopped
            ],
            AgentExecutionStatus.Failed: [
                AgentExecutionStatus.Pending,  # Reset for retry
                AgentExecutionStatus.Stopped
            ],
            AgentExecutionStatus.Completed: [
                AgentExecutionStatus.Pending,  # New task
                AgentExecutionStatus.Stopped
            ],
            AgentExecutionStatus.Stopped: []  # Terminal state
        }
    
    async def transition_to(self, new_status: AgentExecutionStatus, 
                           reason: str = None, **metadata) -> bool:
        """Transition to a new status with validation and callbacks."""
        
        # Validate transition
        if not self._is_valid_transition(self.current_status, new_status):
            error_msg = f"Invalid transition from {self.current_status} to {new_status}"
            print(f"❌ {error_msg}")
            raise StatusManagerError(error_msg)
        
        # Calculate duration in previous status
        duration = time.time() - self.status_start_time
        
        # Record transition
        transition = StatusTransition(
            from_status=self.current_status,
            to_status=new_status,
            reason=reason,
            metadata=metadata,
            duration_seconds=duration
        )
        
        self.status_history.append(transition)
        
        # Update metrics
        self._update_metrics(transition)
        
        # Execute pre-transition callbacks
        await self._execute_transition_callbacks(self.current_status, new_status, transition)
        
        # Update status
        old_status = self.current_status
        self.current_status = new_status
        self.status_start_time = time.time()
        
        # Execute status-specific callbacks
        await self._execute_status_callbacks(new_status, transition)
        
        print(f"🔄 Status transition: {old_status} → {new_status} ({reason or 'no reason'})")
        
        return True
    
    def _is_valid_transition(self, from_status: AgentExecutionStatus, 
                           to_status: AgentExecutionStatus) -> bool:
        """Check if a status transition is valid."""
        return to_status in self.valid_transitions.get(from_status, [])
    
    def _update_metrics(self, transition: StatusTransition):
        """Update status transition metrics."""
        self.metrics["total_transitions"] += 1
        
        # Track status durations
        if transition.from_status not in self.metrics["status_durations"]:
            self.metrics["status_durations"][transition.from_status] = []
        
        if transition.duration_seconds:
            self.metrics["status_durations"][transition.from_status].append(
                transition.duration_seconds
            )
        
        # Track errors and recoveries
        if transition.to_status == AgentExecutionStatus.Error:
            self.metrics["error_count"] += 1
        elif (transition.from_status == AgentExecutionStatus.Error and 
              transition.to_status == AgentExecutionStatus.Executing):
            self.metrics["recovery_count"] += 1
    
    def register_status_callback(self, status: AgentExecutionStatus, callback: Callable):
        """Register callback for specific status."""
        if status not in self.status_callbacks:
            self.status_callbacks[status] = []
        
        self.status_callbacks[status].append(callback)
        print(f"📝 Registered callback for status: {status}")
    
    def register_transition_callback(self, from_status: AgentExecutionStatus, 
                                   to_status: AgentExecutionStatus, callback: Callable):
        """Register callback for specific transition."""
        transition_key = (from_status, to_status)
        
        if transition_key not in self.transition_callbacks:
            self.transition_callbacks[transition_key] = []
        
        self.transition_callbacks[transition_key].append(callback)
        print(f"📝 Registered transition callback: {from_status} → {to_status}")
    
    async def _execute_status_callbacks(self, status: AgentExecutionStatus, 
                                      transition: StatusTransition):
        """Execute callbacks registered for the given status."""
        callbacks = self.status_callbacks.get(status, [])
        
        for callback in callbacks:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(status, transition)
                else:
                    callback(status, transition)
            except Exception as e:
                print(f"❌ Status callback error: {e}")
    
    async def _execute_transition_callbacks(self, from_status: AgentExecutionStatus,
                                          to_status: AgentExecutionStatus,
                                          transition: StatusTransition):
        """Execute callbacks registered for the given transition."""
        transition_key = (from_status, to_status)
        callbacks = self.transition_callbacks.get(transition_key, [])
        
        for callback in callbacks:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(transition)
                else:
                    callback(transition)
            except Exception as e:
                print(f"❌ Transition callback error: {e}")
    
    def get_status_summary(self) -> Dict[str, any]:
        """Get comprehensive status summary."""
        current_duration = time.time() - self.status_start_time
        
        # Calculate average durations
        avg_durations = {}
        for status, durations in self.metrics["status_durations"].items():
            if durations:
                avg_durations[status] = sum(durations) / len(durations)
        
        return {
            "current_status": self.current_status,
            "current_duration_seconds": current_duration,
            "total_transitions": self.metrics["total_transitions"],
            "error_count": self.metrics["error_count"],
            "recovery_count": self.metrics["recovery_count"],
            "average_durations": avg_durations,
            "last_5_transitions": [
                {
                    "from": t.from_status,
                    "to": t.to_status,
                    "timestamp": t.timestamp,
                    "reason": t.reason,
                    "duration": t.duration_seconds
                }
                for t in self.status_history[-5:]
            ]
        }
    
    def is_terminal_state(self) -> bool:
        """Check if current status is terminal."""
        return self.current_status in [
            AgentExecutionStatus.Completed,
            AgentExecutionStatus.Failed,
            AgentExecutionStatus.Stopped
        ]
    
    def is_error_state(self) -> bool:
        """Check if current status indicates an error."""
        return self.current_status in [
            AgentExecutionStatus.Error,
            AgentExecutionStatus.Failed
        ]
    
    def get_uptime_stats(self) -> Dict[str, float]:
        """Get uptime statistics by status."""
        total_time = sum(
            sum(durations) 
            for durations in self.metrics["status_durations"].values()
        ) + (time.time() - self.status_start_time)
        
        if total_time == 0:
            return {}
        
        stats = {}
        for status, durations in self.metrics["status_durations"].items():
            stats[status] = (sum(durations) / total_time) * 100
        
        # Add current status
        current_time = time.time() - self.status_start_time
        stats[self.current_status] = stats.get(self.current_status, 0) + (current_time / total_time) * 100
        
        return stats

# Global status manager
status_manager = AdvancedStatusManager()

@on_boot
async def initialize_status_management():
    """Initialize advanced status management system."""
    print("📊 Initializing status management...")
    
    # Register status-specific callbacks
    status_manager.register_status_callback(
        AgentExecutionStatus.Error, 
        handle_error_status
    )
    
    status_manager.register_status_callback(
        AgentExecutionStatus.Executing,
        handle_executing_status
    )
    
    status_manager.register_status_callback(
        AgentExecutionStatus.Completed,
        handle_completed_status
    )
    
    # Register transition callbacks
    status_manager.register_transition_callback(
        AgentExecutionStatus.Pending,
        AgentExecutionStatus.Executing,
        handle_start_execution
    )
    
    status_manager.register_transition_callback(
        AgentExecutionStatus.Error,
        AgentExecutionStatus.Executing,
        handle_error_recovery
    )
    
    # Transition to executing state
    await status_manager.transition_to(
        AgentExecutionStatus.Executing,
        "Agent initialization completed"
    )
    
    print("✅ Status management initialized")

# Status callback handlers
async def handle_error_status(status: AgentExecutionStatus, transition: StatusTransition):
    """Handle error status with automatic recovery attempts."""
    print(f"🚨 Error status detected: {transition.reason}")
    
    # Log error details
    if "error" in transition.metadata:
        error = transition.metadata["error"]
        print(f"  📋 Error details: {error}")
    
    # Attempt automatic recovery after a delay
    asyncio.create_task(attempt_error_recovery(transition))

async def handle_executing_status(status: AgentExecutionStatus, transition: StatusTransition):
    """Handle executing status with monitoring."""
    print(f"▶️ Execution started: {transition.reason or 'Task processing'}")
    
    # Start execution monitoring
    asyncio.create_task(monitor_execution_health())

async def handle_completed_status(status: AgentExecutionStatus, transition: StatusTransition):
    """Handle completion status with cleanup."""
    print(f"✅ Execution completed: {transition.reason or 'Task finished'}")
    
    # Record completion metrics
    if "task_id" in transition.metadata:
        task_id = transition.metadata["task_id"]
        print(f"  📋 Completed task: {task_id}")

async def handle_start_execution(transition: StatusTransition):
    """Handle start of execution transition."""
    print(f"🚀 Starting execution after {transition.duration_seconds:.2f}s in pending state")

async def handle_error_recovery(transition: StatusTransition):
    """Handle recovery from error state."""
    print(f"🔄 Recovering from error after {transition.duration_seconds:.2f}s")
    status_manager.metrics["recovery_count"] += 1
```

### Automated Recovery Mechanisms

Implement intelligent recovery based on status patterns:

```python
from typing import Dict, List
import asyncio

class AutoRecoveryManager:
    """Automated recovery system based on status patterns."""
    
    def __init__(self, status_manager: AdvancedStatusManager):
        self.status_manager = status_manager
        self.recovery_strategies: Dict[str, Callable] = {}
        self.recovery_history: List[Dict[str, any]] = []
        self.recovery_config = {
            "max_retries": 3,
            "retry_delay": 5.0,
            "recovery_timeout": 30.0,
            "error_threshold": 5
        }
        
    def register_recovery_strategy(self, error_pattern: str, strategy: Callable):
        """Register recovery strategy for specific error patterns."""
        self.recovery_strategies[error_pattern] = strategy
        print(f"🔧 Registered recovery strategy for: {error_pattern}")
    
    async def analyze_and_recover(self, transition: StatusTransition):
        """Analyze error and attempt appropriate recovery."""
        if transition.to_status != AgentExecutionStatus.Error:
            return
        
        error_reason = transition.reason or "unknown_error"
        recovery_strategy = self._find_recovery_strategy(error_reason)
        
        if recovery_strategy:
            recovery_record = {
                "timestamp": time.time(),
                "error_reason": error_reason,
                "strategy": recovery_strategy.__name__,
                "transition": transition
            }
            
            try:
                print(f"🔄 Attempting recovery with strategy: {recovery_strategy.__name__}")
                
                success = await asyncio.wait_for(
                    recovery_strategy(transition),
                    timeout=self.recovery_config["recovery_timeout"]
                )
                
                if success:
                    await self.status_manager.transition_to(
                        AgentExecutionStatus.Executing,
                        f"Recovered using {recovery_strategy.__name__}",
                        recovery_strategy=recovery_strategy.__name__
                    )
                    recovery_record["success"] = True
                    print(f"✅ Recovery successful")
                else:
                    recovery_record["success"] = False
                    await self._handle_recovery_failure(transition)
                
            except asyncio.TimeoutError:
                recovery_record["success"] = False
                recovery_record["timeout"] = True
                print(f"⏰ Recovery timed out after {self.recovery_config['recovery_timeout']}s")
                await self._handle_recovery_failure(transition)
                
            except Exception as e:
                recovery_record["success"] = False
                recovery_record["error"] = str(e)
                print(f"❌ Recovery strategy failed: {e}")
                await self._handle_recovery_failure(transition)
            
            self.recovery_history.append(recovery_record)
        else:
            print(f"⚠️ No recovery strategy found for: {error_reason}")
            await self._handle_recovery_failure(transition)
    
    def _find_recovery_strategy(self, error_reason: str) -> Optional[Callable]:
        """Find appropriate recovery strategy for error reason."""
        for pattern, strategy in self.recovery_strategies.items():
            if pattern.lower() in error_reason.lower():
                return strategy
        
        return self.recovery_strategies.get("default")
    
    async def _handle_recovery_failure(self, transition: StatusTransition):
        """Handle failed recovery attempts."""
        recent_errors = self._count_recent_errors()
        
        if recent_errors >= self.recovery_config["error_threshold"]:
            print(f"🚨 Too many errors ({recent_errors}), transitioning to failed state")
            await self.status_manager.transition_to(
                AgentExecutionStatus.Failed,
                f"Exceeded error threshold ({recent_errors} errors)",
                error_threshold_exceeded=True
            )
        else:
            # Wait before next retry
            await asyncio.sleep(self.recovery_config["retry_delay"])
            print(f"⏳ Waiting {self.recovery_config['retry_delay']}s before next attempt")
    
    def _count_recent_errors(self, time_window: int = 300) -> int:
        """Count errors in recent time window (default 5 minutes)."""
        current_time = time.time()
        recent_errors = 0
        
        for transition in self.status_manager.status_history:
            if (current_time - transition.timestamp <= time_window and
                transition.to_status == AgentExecutionStatus.Error):
                recent_errors += 1
        
        return recent_errors

# Recovery strategies
async def database_connection_recovery(transition: StatusTransition) -> bool:
    """Recovery strategy for database connection errors."""
    print("🔄 Attempting database connection recovery...")
    
    try:
        # Simulate database reconnection
        await asyncio.sleep(2)
        
        # Test connection
        await test_database_connection()
        
        print("✅ Database connection recovered")
        return True
        
    except Exception as e:
        print(f"❌ Database recovery failed: {e}")
        return False

async def api_timeout_recovery(transition: StatusTransition) -> bool:
    """Recovery strategy for API timeout errors."""
    print("🔄 Attempting API timeout recovery...")
    
    try:
        # Increase timeout settings
        # Reset connection pools
        await reset_api_connections()
        
        print("✅ API timeout settings adjusted")
        return True
        
    except Exception as e:
        print(f"❌ API timeout recovery failed: {e}")
        return False

async def memory_pressure_recovery(transition: StatusTransition) -> bool:
    """Recovery strategy for memory pressure errors."""
    print("🔄 Attempting memory pressure recovery...")
    
    try:
        # Force garbage collection
        import gc
        collected = gc.collect()
        
        # Clear caches
        if hasattr(cache_manager, 'clear_cache'):
            await cache_manager.clear_cache()
        
        print(f"✅ Memory recovery: {collected} objects collected")
        return True
        
    except Exception as e:
        print(f"❌ Memory recovery failed: {e}")
        return False

async def default_recovery(transition: StatusTransition) -> bool:
    """Default recovery strategy for unknown errors."""
    print("🔄 Attempting default recovery...")
    
    try:
        # Basic recovery steps
        await asyncio.sleep(1)
        
        # Reset basic resources
        print("✅ Default recovery completed")
        return True
        
    except Exception as e:
        print(f"❌ Default recovery failed: {e}")
        return False

# Initialize recovery manager
recovery_manager = AutoRecoveryManager(status_manager)

@on_boot
async def setup_recovery_strategies():
    """Setup automated recovery strategies."""
    print("🔧 Setting up recovery strategies...")
    
    # Register recovery strategies
    recovery_manager.register_recovery_strategy("database", database_connection_recovery)
    recovery_manager.register_recovery_strategy("timeout", api_timeout_recovery)
    recovery_manager.register_recovery_strategy("memory", memory_pressure_recovery)
    recovery_manager.register_recovery_strategy("default", default_recovery)
    
    # Register recovery manager with status manager
    status_manager.register_status_callback(
        AgentExecutionStatus.Error,
        lambda status, transition: asyncio.create_task(recovery_manager.analyze_and_recover(transition))
    )
    
    print("✅ Recovery strategies configured")

async def attempt_error_recovery(transition: StatusTransition):
    """Attempt error recovery with delay."""
    await asyncio.sleep(2)  # Brief delay before recovery
    await recovery_manager.analyze_and_recover(transition)
```

## Status Monitoring and Alerting

### Real-time Status Dashboard

Create comprehensive status monitoring:

```python
import json
from datetime import datetime, timedelta

class StatusMonitoringDashboard:
    """Real-time status monitoring and alerting system."""
    
    def __init__(self, status_manager: AdvancedStatusManager):
        self.status_manager = status_manager
        self.alert_rules: List[Dict[str, any]] = []
        self.alert_history: List[Dict[str, any]] = []
        self.monitoring_metrics = {
            "alerts_sent": 0,
            "uptime_percentage": 100.0,
            "avg_response_time": 0,
            "error_rate": 0
        }
        self.dashboard_data = {}
        
    def add_alert_rule(self, name: str, condition: Callable, severity: str = "warning",
                      cooldown: int = 300, message: str = None):
        """Add monitoring alert rule."""
        rule = {
            "name": name,
            "condition": condition,
            "severity": severity,
            "cooldown": cooldown,
            "message": message or f"Alert: {name}",
            "last_triggered": 0
        }
        
        self.alert_rules.append(rule)
        print(f"🚨 Added alert rule: {name} ({severity})")
    
    async def check_alerts(self):
        """Check all alert conditions and trigger alerts if needed."""
        current_time = time.time()
        status_summary = self.status_manager.get_status_summary()
        
        for rule in self.alert_rules:
            # Check cooldown
            if current_time - rule["last_triggered"] < rule["cooldown"]:
                continue
            
            try:
                # Evaluate alert condition
                if rule["condition"](status_summary, self.monitoring_metrics):
                    await self._trigger_alert(rule, status_summary)
                    rule["last_triggered"] = current_time
                    
            except Exception as e:
                print(f"❌ Alert rule evaluation error ({rule['name']}): {e}")
    
    async def _trigger_alert(self, rule: Dict[str, any], context: Dict[str, any]):
        """Trigger alert and record in history."""
        alert = {
            "timestamp": time.time(),
            "rule_name": rule["name"],
            "severity": rule["severity"],
            "message": rule["message"],
            "context": context
        }
        
        self.alert_history.append(alert)
        self.monitoring_metrics["alerts_sent"] += 1
        
        # Send alert (customize based on severity)
        await self._send_alert(alert)
        
        print(f"🚨 {rule['severity'].upper()} ALERT: {rule['message']}")
    
    async def _send_alert(self, alert: Dict[str, any]):
        """Send alert through configured channels."""
        # Customize based on your alerting infrastructure
        severity = alert["severity"]
        
        if severity == "critical":
            # Send immediate notification
            await self._send_critical_alert(alert)
        elif severity == "warning":
            # Send standard notification
            await self._send_warning_alert(alert)
        else:
            # Log only
            print(f"📝 Info alert: {alert['message']}")
    
    async def _send_critical_alert(self, alert: Dict[str, any]):
        """Send critical alert through priority channels."""
        # Implementation for critical alerts (email, SMS, Slack, etc.)
        print(f"🔴 CRITICAL: {alert['message']}")
        
        # Example: Send to monitoring system
        # await monitoring_system.send_alert(alert)
    
    async def _send_warning_alert(self, alert: Dict[str, any]):
        """Send warning alert through standard channels."""
        # Implementation for warning alerts
        print(f"🟡 WARNING: {alert['message']}")
    
    def update_dashboard_data(self):
        """Update dashboard data with current metrics."""
        status_summary = self.status_manager.get_status_summary()
        uptime_stats = self.status_manager.get_uptime_stats()
        
        self.dashboard_data = {
            "timestamp": datetime.now().isoformat(),
            "current_status": status_summary["current_status"],
            "uptime_stats": uptime_stats,
            "error_count": status_summary["error_count"],
            "recovery_count": status_summary["recovery_count"],
            "recent_transitions": status_summary["last_5_transitions"],
            "alerts": {
                "active_alerts": len([
                    alert for alert in self.alert_history[-10:]
                    if time.time() - alert["timestamp"] < 3600  # Last hour
                ]),
                "total_alerts": len(self.alert_history)
            },
            "performance": self.monitoring_metrics
        }
    
    def get_dashboard_json(self) -> str:
        """Get dashboard data as JSON."""
        self.update_dashboard_data()
        return json.dumps(self.dashboard_data, indent=2, default=str)
    
    async def generate_status_report(self, period_hours: int = 24) -> Dict[str, any]:
        """Generate comprehensive status report for given period."""
        end_time = time.time()
        start_time = end_time - (period_hours * 3600)
        
        # Filter transitions in time period
        period_transitions = [
            t for t in self.status_manager.status_history
            if start_time <= t.timestamp <= end_time
        ]
        
        # Calculate metrics for period
        total_time = period_hours * 3600
        status_time = {}
        error_count = 0
        
        for transition in period_transitions:
            if transition.duration_seconds:
                status_time[transition.from_status] = (
                    status_time.get(transition.from_status, 0) + 
                    transition.duration_seconds
                )
            
            if transition.to_status == AgentExecutionStatus.Error:
                error_count += 1
        
        # Calculate uptime percentage
        executing_time = status_time.get(AgentExecutionStatus.Executing, 0)
        uptime_percentage = (executing_time / total_time) * 100 if total_time > 0 else 0
        
        # Get alerts in period
        period_alerts = [
            alert for alert in self.alert_history
            if start_time <= alert["timestamp"] <= end_time
        ]
        
        return {
            "period": {
                "hours": period_hours,
                "start_time": datetime.fromtimestamp(start_time).isoformat(),
                "end_time": datetime.fromtimestamp(end_time).isoformat()
            },
            "summary": {
                "uptime_percentage": uptime_percentage,
                "total_transitions": len(period_transitions),
                "error_count": error_count,
                "alert_count": len(period_alerts)
            },
            "status_distribution": {
                status: (time_spent / total_time) * 100
                for status, time_spent in status_time.items()
            },
            "alerts_by_severity": {
                severity: len([a for a in period_alerts if a["severity"] == severity])
                for severity in ["info", "warning", "critical"]
            }
        }

# Initialize monitoring dashboard
monitoring_dashboard = StatusMonitoringDashboard(status_manager)

# Define alert conditions
def high_error_rate_condition(status_summary: Dict, metrics: Dict) -> bool:
    """Check for high error rate."""
    total_transitions = status_summary.get("total_transitions", 0)
    error_count = status_summary.get("error_count", 0)
    
    if total_transitions < 10:  # Not enough data
        return False
    
    error_rate = (error_count / total_transitions) * 100
    return error_rate > 10  # Alert if error rate > 10%

def stuck_in_error_condition(status_summary: Dict, metrics: Dict) -> bool:
    """Check if agent is stuck in error state."""
    return (status_summary.get("current_status") == AgentExecutionStatus.Error and
            status_summary.get("current_duration_seconds", 0) > 300)  # 5 minutes

def low_uptime_condition(status_summary: Dict, metrics: Dict) -> bool:
    """Check for low uptime percentage."""
    uptime_stats = status_manager.get_uptime_stats()
    executing_percentage = uptime_stats.get(AgentExecutionStatus.Executing, 0)
    return executing_percentage < 70  # Alert if < 70% uptime

@on_boot
async def setup_monitoring_alerts():
    """Setup monitoring alerts."""
    print("🚨 Setting up monitoring alerts...")
    
    # Add alert rules
    monitoring_dashboard.add_alert_rule(
        name="High Error Rate",
        condition=high_error_rate_condition,
        severity="warning",
        cooldown=600,  # 10 minutes
        message="Agent error rate exceeds 10%"
    )
    
    monitoring_dashboard.add_alert_rule(
        name="Stuck in Error State",
        condition=stuck_in_error_condition,
        severity="critical",
        cooldown=300,  # 5 minutes
        message="Agent stuck in error state for >5 minutes"
    )
    
    monitoring_dashboard.add_alert_rule(
        name="Low Uptime",
        condition=low_uptime_condition,
        severity="warning",
        cooldown=1800,  # 30 minutes
        message="Agent uptime below 70%"
    )
    
    # Start periodic monitoring
    asyncio.create_task(periodic_monitoring())
    
    print("✅ Monitoring alerts configured")

async def periodic_monitoring():
    """Periodic monitoring and alerting."""
    while True:
        try:
            await asyncio.sleep(60)  # Check every minute
            
            # Check alerts
            await monitoring_dashboard.check_alerts()
            
            # Update metrics
            monitoring_dashboard.monitoring_metrics["uptime_percentage"] = (
                status_manager.get_uptime_stats().get(AgentExecutionStatus.Executing, 0)
            )
            
            # Log current status periodically
            if int(time.time()) % 300 == 0:  # Every 5 minutes
                summary = status_manager.get_status_summary()
                print(f"📊 Status: {summary['current_status']} "
                      f"(Errors: {summary['error_count']}, "
                      f"Recoveries: {summary['recovery_count']})")
                
        except Exception as e:
            print(f"⚠️ Monitoring error: {e}")

async def monitor_execution_health():
    """Monitor execution health during active processing."""
    max_execution_time = 600  # 10 minutes
    start_time = time.time()
    
    while (status_manager.current_status == AgentExecutionStatus.Executing and
           time.time() - start_time < max_execution_time):
        
        await asyncio.sleep(30)  # Check every 30 seconds
        
        # Check if execution is taking too long
        execution_time = time.time() - start_time
        if execution_time > max_execution_time:
            await status_manager.transition_to(
                AgentExecutionStatus.Error,
                "Execution timeout exceeded",
                execution_time=execution_time,
                timeout_threshold=max_execution_time
            )
            break
```

## Integration with Existing Systems

### Task Integration with Status Management

Integrate status management with task processing:

```python
@on_task
async def status_aware_task_handler(task):
    """Task handler with comprehensive status management."""
    task_id = task.id
    user_id = task.input.user.id if task.input.user else "anonymous"
    
    try:
        # Transition to executing state
        await status_manager.transition_to(
            AgentExecutionStatus.Executing,
            f"Starting task {task_id}",
            task_id=task_id,
            user_id=user_id,
            task_type=getattr(task.input, 'task_type', 'general')
        )
        
        # Process the task
        result = await process_task_with_monitoring(task)
        
        # Transition to completed state
        await status_manager.transition_to(
            AgentExecutionStatus.Completed,
            f"Task {task_id} completed successfully",
            task_id=task_id,
            result_size=len(str(result)),
            processing_time=time.time() - status_manager.status_start_time
        )
        
        task.result = result
        return task
        
    except Exception as e:
        # Transition to error state
        await status_manager.transition_to(
            AgentExecutionStatus.Error,
            f"Task {task_id} failed: {str(e)}",
            task_id=task_id,
            error=str(e),
            error_type=type(e).__name__
        )
        
        # Re-raise for higher-level handling
        raise

async def process_task_with_monitoring(task):
    """Process task with status monitoring."""
    # Simulate task processing with status updates
    await asyncio.sleep(0.1)
    
    # Simulate potential error conditions
    if "error" in task.input.text.lower():
        raise ValueError("Simulated task error")
    
    return f"Processed: {task.input.text}"

# Utility functions for helper methods
async def test_database_connection():
    """Test database connection."""
    await asyncio.sleep(0.1)
    return True

async def reset_api_connections():
    """Reset API connections."""
    await asyncio.sleep(0.1)
    return True
```

### Status-based Performance Optimization

Optimize agent performance based on status patterns:

```python
class StatusBasedOptimizer:
    """Optimize agent behavior based on status patterns."""
    
    def __init__(self, status_manager: AdvancedStatusManager):
        self.status_manager = status_manager
        self.optimization_history = []
        self.current_optimizations = set()
    
    async def analyze_and_optimize(self):
        """Analyze status patterns and apply optimizations."""
        status_summary = self.status_manager.get_status_summary()
        
        # Check for optimization opportunities
        if self._should_optimize_for_errors(status_summary):
            await self._apply_error_reduction_optimizations()
        
        if self._should_optimize_for_performance(status_summary):
            await self._apply_performance_optimizations()
        
        if self._should_optimize_for_stability(status_summary):
            await self._apply_stability_optimizations()
    
    def _should_optimize_for_errors(self, status_summary: Dict) -> bool:
        """Check if error-reduction optimizations are needed."""
        error_count = status_summary.get("error_count", 0)
        total_transitions = status_summary.get("total_transitions", 0)
        
        if total_transitions < 10:
            return False
        
        error_rate = (error_count / total_transitions) * 100
        return error_rate > 5 and "error_reduction" not in self.current_optimizations
    
    def _should_optimize_for_performance(self, status_summary: Dict) -> bool:
        """Check if performance optimizations are needed."""
        avg_durations = status_summary.get("average_durations", {})
        executing_duration = avg_durations.get(AgentExecutionStatus.Executing, 0)
        
        return (executing_duration > 30 and  # Tasks taking > 30 seconds
                "performance" not in self.current_optimizations)
    
    def _should_optimize_for_stability(self, status_summary: Dict) -> bool:
        """Check if stability optimizations are needed."""
        recent_transitions = status_summary.get("last_5_transitions", [])
        
        # Check for frequent state changes (instability)
        if len(recent_transitions) >= 5:
            time_span = recent_transitions[-1]["timestamp"] - recent_transitions[0]["timestamp"]
            transition_rate = len(recent_transitions) / max(time_span, 1)
            return (transition_rate > 0.1 and  # > 1 transition per 10 seconds
                    "stability" not in self.current_optimizations)
        
        return False
    
    async def _apply_error_reduction_optimizations(self):
        """Apply optimizations to reduce error rate."""
        print("🔧 Applying error reduction optimizations...")
        
        self.current_optimizations.add("error_reduction")
        
        # Increase timeouts
        await self._adjust_timeout_settings(multiplier=1.5)
        
        # Enable more aggressive retry logic
        await self._enable_enhanced_retries()
        
        # Record optimization
        self.optimization_history.append({
            "timestamp": time.time(),
            "type": "error_reduction",
            "details": "Increased timeouts, enhanced retries"
        })
        
        print("✅ Error reduction optimizations applied")
    
    async def _apply_performance_optimizations(self):
        """Apply optimizations to improve performance."""
        print("🚀 Applying performance optimizations...")
        
        self.current_optimizations.add("performance")
        
        # Enable caching
        await self._enable_aggressive_caching()
        
        # Optimize connection pools
        await self._optimize_connection_pools()
        
        # Record optimization
        self.optimization_history.append({
            "timestamp": time.time(),
            "type": "performance",
            "details": "Enabled caching, optimized connections"
        })
        
        print("✅ Performance optimizations applied")
    
    async def _apply_stability_optimizations(self):
        """Apply optimizations to improve stability."""
        print("⚖️ Applying stability optimizations...")
        
        self.current_optimizations.add("stability")
        
        # Add delays between operations
        await self._enable_operation_throttling()
        
        # Enable health checks
        await self._enable_enhanced_health_checks()
        
        # Record optimization
        self.optimization_history.append({
            "timestamp": time.time(),
            "type": "stability",
            "details": "Enabled throttling, enhanced health checks"
        })
        
        print("✅ Stability optimizations applied")
    
    async def _adjust_timeout_settings(self, multiplier: float):
        """Adjust timeout settings."""
        # Implementation would adjust actual timeout values
        print(f"  🕐 Adjusted timeouts by {multiplier}x")
    
    async def _enable_enhanced_retries(self):
        """Enable enhanced retry logic."""
        # Implementation would configure retry settings
        print("  🔄 Enhanced retry logic enabled")
    
    async def _enable_aggressive_caching(self):
        """Enable aggressive caching strategies."""
        # Implementation would configure caching
        print("  🧠 Aggressive caching enabled")
    
    async def _optimize_connection_pools(self):
        """Optimize connection pool settings."""
        # Implementation would adjust pool sizes
        print("  🔗 Connection pools optimized")
    
    async def _enable_operation_throttling(self):
        """Enable operation throttling."""
        # Implementation would add throttling
        print("  ⏸️ Operation throttling enabled")
    
    async def _enable_enhanced_health_checks(self):
        """Enable enhanced health checking."""
        # Implementation would configure health checks
        print("  🏥 Enhanced health checks enabled")

# Initialize optimizer
status_optimizer = StatusBasedOptimizer(status_manager)

@on_boot
async def setup_status_optimization():
    """Setup status-based optimization."""
    print("🔧 Setting up status-based optimization...")
    
    # Start periodic optimization
    asyncio.create_task(periodic_optimization())
    
    print("✅ Status-based optimization configured")

async def periodic_optimization():
    """Periodically analyze and optimize based on status."""
    while True:
        try:
            await asyncio.sleep(1800)  # Check every 30 minutes
            await status_optimizer.analyze_and_optimize()
            
        except Exception as e:
            print(f"⚠️ Optimization error: {e}")

@on_shutdown
async def generate_final_status_report():
    """Generate comprehensive final status report."""
    print("📊 Generating final status report...")
    
    # Generate 24-hour report
    report = await monitoring_dashboard.generate_status_report(24)
    
    print("📋 Final Status Report Summary:")
    print(f"  ⏱️ Uptime: {report['summary']['uptime_percentage']:.1f}%")
    print(f"  🔄 Transitions: {report['summary']['total_transitions']}")
    print(f"  ❌ Errors: {report['summary']['error_count']}")
    print(f"  🚨 Alerts: {report['summary']['alert_count']}")
    
    # Save detailed report
    try:
        with open("status_report.json", "w") as f:
            json.dump(report, f, indent=2, default=str)
        print("💾 Detailed status report saved to status_report.json")
    except Exception as e:
        print(f"⚠️ Could not save status report: {e}")
    
    # Final status transition
    await status_manager.transition_to(
        AgentExecutionStatus.Stopped,
        "Agent shutdown completed",
        final_report=report
    )
```

## Related Documentation

- [MCP Integration Guide](/user-guide/backend-configuration/mcp-integration-guide): Status monitoring for MCP tools
- [Lifecycle Management](/user-guide/backend-configuration/lifecycle-management): Status during agent lifecycle
- [Performance Best Practices](/user-guide/backend-configuration/performance-best-practices): Performance-driven status management
- [API Reference: Types](/API reference/types): AgentExecutionStatus enumeration
- [API Reference: Tasks](/API reference/tasks): Task status integration