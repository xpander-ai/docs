---
title: "Agent"
description: "Core AI Agent class for executing tasks and tools"
icon: "robot"
---

The `Agent` class is the central component of the xpander.ai SDK, representing an AI agent capable of executing tasks, using tools, and maintaining conversational state.

## Overview

An Agent has several key capabilities:
- Running tasks and managing execution flow
- Executing tools and function calls
- Managing conversation memory and state
- Building and navigating graph-based workflows
- Integrating with external services through agentic interfaces

<Note>
All agent instances are retrieved from the XpanderClient. You typically won't create Agent instances directly.
</Note>

## Retrieving an Agent

<CodeGroup>
```python Python
from xpander_sdk import XpanderClient
from dotenv import load_dotenv
import os

# Load environment variables
load_dotenv()
XPANDER_API_KEY = os.environ["XPANDER_API_KEY"]
AGENT_ID = os.environ["AGENT_ID"]

# Initialize the client
client = XpanderClient(api_key=XPANDER_API_KEY)

# Get an agent by ID
agent = client.agents.get(agent_id=AGENT_ID)

# Access basic properties
print(f"Agent ID: {agent.id}")
print(f"Agent Name: {agent.name}")
print(f"Description: {agent.metadata.description}")
```

```typescript TypeScript
import { XpanderClient } from '@xpander-ai/sdk';
import * as dotenv from 'dotenv';

// Load environment variables
dotenv.config();
const XPANDER_API_KEY = process.env.XPANDER_API_KEY;
const AGENT_ID = process.env.AGENT_ID;

// Get an agent (async function)
async function getAgent() {
  // Initialize the client
  const client = new XpanderClient({ apiKey: XPANDER_API_KEY });
  
  // Get an agent by ID
  const agent = await client.agents.get({ agentId: AGENT_ID });
  
  // Access basic properties
  console.log(`Agent ID: ${agent.id}`);
  console.log(`Agent Name: ${agent.name}`);
  console.log(`Description: ${agent.metadata.description}`);
  
  return agent;
}
```
</CodeGroup>

## Core Properties

| Property       | Type            | Description                                          | Availability                |
|----------------|-----------------|------------------------------------------------------|----------------------------|
| `id`           | string          | Unique identifier for the agent                      | Always available           |
| `name`         | string          | Name of the agent                                    | Always available           |
| `instructions` | string          | System instructions for the agent                    | Always available           |
| `metadata`     | object          | Contains metadata like description                   | Always available           |
| `execution`    | Execution       | Current execution context                            | After adding a task        |
| `memory`       | Memory          | Memory management interface                          | Always available           |
| `messages`     | List[Dict]      | Conversation messages                                | After memory initialization|
| `graph`        | Graph           | Workflow graph system                                | Always available           |
| `tool_choice`  | string          | Setting for tool selection behavior                  | Always available           |

<Warning>
Some properties require initialization before they can be accessed. For example, the `execution` property is only available after calling `add_task()` (Python) or `addTask()` (TypeScript), and `messages` is only available after initializing memory with `memory.init_messages()` (Python) or `memory.initMessages()` (TypeScript).
</Warning>

## Initialization Sequence

Most agents follow this initialization sequence:

<Steps>
  <Step title="Get an agent">
    <CodeGroup>
      ```python Python
      agent = client.agents.get(agent_id=AGENT_ID)
      ```
      
      ```typescript TypeScript
      const agent = await client.agents.get({ agentId: AGENT_ID });
      ```
    </CodeGroup>
  </Step>
  <Step title="Add a task">
    <CodeGroup>
      ```python Python
      agent.add_task(input="Find information about AI startups")
      ```
      
      ```typescript TypeScript
      await agent.addTask({ input: "Find information about AI startups" });
      ```
    </CodeGroup>
  </Step>
  <Step title="Initialize memory">
    <CodeGroup>
      ```python Python
      agent.memory.init_messages(
          input=agent.execution.input_message,
          instructions=agent.instructions,
          llm_provider=LLMProvider.OPEN_AI
      )
      ```
      
      ```typescript TypeScript
      await agent.memory.initMessages({
          input: agent.execution.inputMessage,
          instructions: agent.instructions,
          llmProvider: LLMProvider.OPEN_AI
      });
      ```
    </CodeGroup>
  </Step>
  <Step title="Run the agent loop">
    <CodeGroup>
      ```python Python
      while not agent.is_finished():
          # Run LLM and process tools
          # ...
      ```
      
      ```typescript TypeScript
      while (!(await agent.isFinished())) {
          // Run LLM and process tools
          // ...
      }
      ```
    </CodeGroup>
  </Step>
</Steps>

## Task Management Methods

### add_task() / addTask()

Adds a new task for the agent to process.

<CodeGroup>
```python Python
# Basic task
execution = agent.add_task(input="Find information about AI startups")

# Task with files
execution = agent.add_task(
    input="Analyze this document",
    files=[{
        "content": "Content of document...",
        "name": "document.txt"
    }],
    use_worker=True
)

# Access execution properties
print(f"Execution status: {agent.execution.status}")
print(f"Input message: {agent.execution.input_message}")
```

```typescript TypeScript
// Basic task
const execution = await agent.addTask({ input: "Find information about AI startups" });

// Task with files
const executionWithFiles = await agent.addTask({
    input: "Analyze this document",
    files: [{
        content: "Content of document...",
        name: "document.txt"
    }],
    useWorker: true
});

// Access execution properties
console.log(`Execution status: ${agent.execution.status}`);
console.log(`Input message: ${agent.execution.inputMessage}`);
```
</CodeGroup>

#### Parameters

| Parameter    | Type         | Required | Description                              |
|--------------|--------------|----------|------------------------------------------|
| `input`      | string       | Yes      | Task description or user query           |
| `files`      | List[Dict]   | No       | Files to include with the task           |
| `use_worker` | boolean      | No       | Whether to use async worker (default: True) |
| `thread_id`  | string       | No       | Thread ID for conversation continuity    |

#### Returns

Returns an `Execution` object representing the new task.

<Expandable title="Example Response">
<CodeGroup>
  ```python Python
  Execution(
      id="exec_1234abcd",
      status="RUNNING",
      input_message="Find information about AI startups",
      created_at="2023-11-15T14:23:12Z"
  )
  ```
  
  ```typescript TypeScript
  {
      id: "exec_1234abcd",
      status: "RUNNING",
      inputMessage: "Find information about AI startups",
      createdAt: "2023-11-15T14:23:12Z"
  }
  ```
</CodeGroup>
</Expandable>

### is_finished() / isFinished()

Checks if the current task execution is finished.

<CodeGroup>
```python Python
# Run until execution is complete
while not agent.is_finished():
    # Run execution cycle
    pass

# After completion
print("Task completed!")
```

```typescript TypeScript
// Run until execution is complete
while (!(await agent.isFinished())) {
    // Run execution cycle
}

// After completion
console.log("Task completed!");
```
</CodeGroup>

#### Returns

Returns a boolean: `True` if the execution is completed, `False` otherwise.

<Note>
For multi-agent workflows, you can enforce transitions to the next agent without checking `is_finished()`. This allows you to implement custom transition logic based on your specific requirements rather than relying on the agent's built-in completion status. See [Enforcing Agent Transitions Without Manager](/docs/02-agent-builder/07-seqence-agent-teams) for details on implementing this advanced pattern.
</Note>

### retrieve_execution_result() / retrieveExecutionResult()

Gets the result of the current execution.

<CodeGroup>
```python Python
# Get the execution result
execution_result = agent.retrieve_execution_result()

# Access result properties
print(f"Status: {execution_result.status}")
print(f"Result: {execution_result.result}")

# Check for errors
if execution_result.error:
    print(f"Error: {execution_result.error}")
```

```typescript TypeScript
// Get the execution result
const executionResult = await agent.retrieveExecutionResult();

// Access result properties
console.log(`Status: ${executionResult.status}`);
console.log(`Result: ${executionResult.result}`);

// Check for errors
if (executionResult.error) {
    console.log(`Error: ${executionResult.error}`);
}
```
</CodeGroup>

#### Returns

Returns an `ExecutionResult` object containing status and result content.

<Expandable title="Example Response">
<CodeGroup>
  ```python Python
  ExecutionResult(
      status="COMPLETED",
      result="I found several AI startups in San Francisco. The most notable ones are:\n\n1. OpenAI - Focusing on general AI and large language models\n2. Anthropic - Working on safe, interpretable AI systems\n3. Scale AI - Providing data labeling services for AI\n4. xpander.ai.ai - Developing agent automation frameworks",
      error=None
  )
  ```
  
  ```typescript TypeScript
  {
      status: "COMPLETED",
      result: "I found several AI startups in San Francisco. The most notable ones are:\n\n1. OpenAI - Focusing on general AI and large language models\n2. Anthropic - Working on safe, interpretable AI systems\n3. Scale AI - Providing data labeling services for AI\n4. xpander.ai.ai - Developing agent automation frameworks",
      error: null
  }
  ```
</CodeGroup>
</Expandable>

## Memory Management Methods

### memory.init_messages() / memory.initMessages()

Initializes the agent's memory with the task input and instructions.

<CodeGroup>
```python Python
# Initialize memory after adding a task
agent.memory.init_messages(
    input=agent.execution.input_message,
    instructions=agent.instructions,
    llm_provider=LLMProvider.OPEN_AI
)

# Check that messages are available
print(f"Message count: {len(agent.messages)}")
for message in agent.messages:
    print(f"Role: {message['role']}, Content: {message['content'][:50]}...")
```

```typescript TypeScript
// Initialize memory after adding a task
await agent.memory.initMessages({
    input: agent.execution.inputMessage,
    instructions: agent.instructions,
    llmProvider: LLMProvider.OPEN_AI
});

// Check that messages are available
console.log(`Message count: ${agent.messages.length}`);
for (const message of agent.messages) {
    console.log(`Role: ${message.role}, Content: ${message.content?.substring(0, 50)}...`);
}
```
</CodeGroup>

#### Parameters

| Parameter       | Type           | Required | Description                                           |
|-----------------|----------------|----------|-------------------------------------------------------|
| `input`         | string         | Yes      | Input message to initialize with                      |
| `instructions`  | string         | Yes      | System instructions for the agent                     |
| `llm_provider`  | LLMProvider    | No       | The LLM provider type (default: LLMProvider.OPEN_AI)  |

### add_messages() / addMessages()

Adds messages to the agent's conversation memory.

<CodeGroup>
```python Python
# Get response from LLM
response = openai_client.chat.completions.create(
    model="gpt-4o",
    messages=agent.messages,
    tools=agent.get_tools(),
    tool_choice="auto"
)

# Add LLM response to memory
agent.add_messages(messages=response.model_dump())

# Check updated message count
print(f"Updated message count: {len(agent.messages)}")
```

```typescript TypeScript
// Get response from LLM
const response = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: agent.messages,
    tools: agent.getTools({ llmProvider: LLMProvider.OPEN_AI }),
    tool_choice: "auto"
});

// Add LLM response to memory
await agent.addMessages({ messages: response });

// Check updated message count
console.log(`Updated message count: ${agent.messages.length}`);
```
</CodeGroup>

#### Parameters

| Parameter   | Type  | Required | Description                                 |
|-------------|-------|----------|---------------------------------------------|
| `messages`  | Dict  | Yes      | Messages to add (e.g., LLM response)        |

## Complete Example

Here's a complete example of using an Agent to execute a task:

<CodeGroup>
```python Python
from xpander_sdk import XpanderClient, LLMProvider
from openai import OpenAI
from dotenv import load_dotenv
import os

# Load environment variables
load_dotenv()
XPANDER_API_KEY = os.environ["XPANDER_API_KEY"]
OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
AGENT_ID = os.environ["AGENT_ID"]

# Initialize clients
xpander_client = XpanderClient(api_key=XPANDER_API_KEY)
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# Get the agent
agent = xpander_client.agents.get(agent_id=AGENT_ID)
print(f"Agent: {agent.name} ({agent.id})")

# Add a task
agent.add_task(input="Find the top 3 AI startups in San Francisco and their main products")

# Initialize memory
agent.memory.init_messages(
    input=agent.execution.input_message,
    instructions=agent.instructions,
    llm_provider=LLMProvider.OPEN_AI
)

# Run the agent until the task is complete
while not agent.is_finished():
    # Get next action from LLM
    response = openai_client.chat.completions.create(
        model="gpt-4o",
        messages=agent.messages,
        tools=agent.get_tools(),
        tool_choice="auto",
        temperature=0.0
    )
    
    # Add LLM response to memory
    agent.add_messages(messages=response.model_dump())
    
    # Extract tool calls
    tool_calls = XpanderClient.extract_tool_calls(
        llm_response=response.model_dump(),
        llm_provider=LLMProvider.OPEN_AI
    )
    
    # Run the tools
    if tool_calls:
        results = agent.run_tools(tool_calls=tool_calls)
        print(f"Executed {len(results)} tools")

# Get and print the final result
result = agent.retrieve_execution_result()
print("\nFINAL RESULT:")
print("=" * 50)
print(result.result)
```

```typescript TypeScript
import { XpanderClient, LLMProvider } from '@xpander-ai/sdk';
import OpenAI from 'openai';
import * as dotenv from 'dotenv';

// Load environment variables
dotenv.config();
const XPANDER_API_KEY = process.env.XPANDER_API_KEY as string;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY as string;
const AGENT_ID = process.env.AGENT_ID as string;

async function runAgent() {
    // Initialize clients
    const xpanderClient = new XpanderClient({ apiKey: XPANDER_API_KEY });
    const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

    // Get the agent
    const agent = await xpanderClient.agents.get({ agentId: AGENT_ID });
    console.log(`Agent: ${agent.name} (${agent.id})`);

    // Add a task
    await agent.addTask({ 
        input: "Find the top 3 AI startups in San Francisco and their main products" 
    });

    // Initialize memory
    await agent.memory.initMessages({
        input: agent.execution.inputMessage,
        instructions: agent.instructions,
        llmProvider: LLMProvider.OPEN_AI
    });

    // Run the agent until the task is complete
    while (!(await agent.isFinished())) {
        // Get next action from LLM
        const response = await openai.chat.completions.create({
            model: "gpt-4o",
            messages: agent.messages,
            tools: agent.getTools({ llmProvider: LLMProvider.OPEN_AI }),
            tool_choice: "auto",
            temperature: 0
        });
        
        // Add LLM response to memory
        await agent.addMessages({ messages: response });
        
        // Extract tool calls
        const toolCalls = XpanderClient.extractToolCalls({
            llmResponse: response,
            llmProvider: LLMProvider.OPEN_AI
        });
        
        // Run the tools
        if (toolCalls.length > 0) {
            const results = await agent.runTools({ toolCalls });
            console.log(`Executed ${results.length} tools`);
        }
    }

    // Get and print the final result
    const result = await agent.retrieveExecutionResult();
    console.log("\nFINAL RESULT:");
    console.log("=".repeat(50));
    console.log(result.result);
}

runAgent().catch(console.error);
```
</CodeGroup>

## Related Guides

<CardGroup cols={2}>
  <Card title="Agent Tools" icon="wrench" href="/api-reference/07-sdk/agent/tools">
    Learn how to work with Agent tools and function calling
  </Card>
  <Card title="Memory Management" icon="brain" href="/api-reference/07-sdk/agent/memory">
    Detailed documentation on agent memory
  </Card>
  <Card title="Graph System" icon="diagram-project" href="/api-reference/07-sdk/agent/graph">
    Learn how to build graph-based workflows
  </Card>
  <Card title="Agentic Interfaces" icon="plug" href="/api-reference/07-sdk/agent/interfaces">
    Connecting to external APIs and services
  </Card>
</CardGroup> 